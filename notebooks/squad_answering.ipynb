{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"squad_answering.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"b68304ea5e36411aae7636318f0be5e2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a30baef17aa84d5ca9d37c67bc7aea2a","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_cc973cc3b1494c0c93444e6a6f992a18","IPY_MODEL_160b6a16267344daa1972e26d67a3775"]}},"a30baef17aa84d5ca9d37c67bc7aea2a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cc973cc3b1494c0c93444e6a6f992a18":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_3b02be962a1b4ed3a18fd1fff8e00f61","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a35f1c628b264ce5ae32ef67c5eced2e"}},"160b6a16267344daa1972e26d67a3775":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a6bd88e147f84e6791b7b1ff8dacb6ab","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:19&lt;00:00, 12.0kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_095f0a319ea044138c36e6856f5e82ad"}},"3b02be962a1b4ed3a18fd1fff8e00f61":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a35f1c628b264ce5ae32ef67c5eced2e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a6bd88e147f84e6791b7b1ff8dacb6ab":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"095f0a319ea044138c36e6856f5e82ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b5f0f5a5477a4bdd84ff75b336a40637":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_c8c43401ccec43578883b6cba3d91ad7","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_906fa06e6f1847d0aac133c6a28ccfc2","IPY_MODEL_a16fddb3c717484a87fdfc9f77ca9301"]}},"c8c43401ccec43578883b6cba3d91ad7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"906fa06e6f1847d0aac133c6a28ccfc2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d8fd5991adff47a6ac0f9fe1f2a31865","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":466062,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":466062,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_94bdb9c2063e44f5973a87c5b16d5f2c"}},"a16fddb3c717484a87fdfc9f77ca9301":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b983adb444ba49c2954a63d288d8be01","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 466k/466k [00:00&lt;00:00, 3.55MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0de889d804a046ecb5b605692f78e02b"}},"d8fd5991adff47a6ac0f9fe1f2a31865":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"94bdb9c2063e44f5973a87c5b16d5f2c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b983adb444ba49c2954a63d288d8be01":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0de889d804a046ecb5b605692f78e02b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8946e465ba8c428ab9891731dc49ec36":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_5a92436f43964b8b8affe54252977a17","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_0e882124f5bb45d5a4aa7d2cd7e7413f","IPY_MODEL_4c104617820e46879d553ae173a5b8c1"]}},"5a92436f43964b8b8affe54252977a17":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0e882124f5bb45d5a4aa7d2cd7e7413f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_1233df069a504af68461f94f9073799d","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d4ea9497613f4848950e49e4c4e5d7fd"}},"4c104617820e46879d553ae173a5b8c1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6adba28b38b4442e9fb33a3a8c7c0ecf","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:00&lt;00:00, 3.35MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_257b047b5105446b9e81cc02d4199354"}},"1233df069a504af68461f94f9073799d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"d4ea9497613f4848950e49e4c4e5d7fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6adba28b38b4442e9fb33a3a8c7c0ecf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"257b047b5105446b9e81cc02d4199354":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0576dff7461c4b99a9d02f06a43567d6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ff368e32e73a4a5a8b8c0060b360ad32","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_13bd49e5a8b24b74a95115b91df92afb","IPY_MODEL_09f142c780424faaa3447ad183aa083d"]}},"ff368e32e73a4a5a8b8c0060b360ad32":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"13bd49e5a8b24b74a95115b91df92afb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0de6f119d49244bd86758b816d565a3c","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":442,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":442,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6064e702bf074b05a3b7bb27877238bb"}},"09f142c780424faaa3447ad183aa083d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c13c95ba55444c79a48e0ba6e21ace40","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 442/442 [00:00&lt;00:00, 2.52kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ddeb5cee7af949c2b4171e494c56ebf3"}},"0de6f119d49244bd86758b816d565a3c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"6064e702bf074b05a3b7bb27877238bb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c13c95ba55444c79a48e0ba6e21ace40":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ddeb5cee7af949c2b4171e494c56ebf3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c4662ceb1d2a44e0bd7a1cad08c70c3b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a0c9cdb0fc954ff9bbe6d264a760be9c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ce3e2c06432a49ca8aa2bd1952adf08f","IPY_MODEL_e244ffb162914c1dbe9b5b89f0e6f242"]}},"a0c9cdb0fc954ff9bbe6d264a760be9c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ce3e2c06432a49ca8aa2bd1952adf08f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_482044f4db2545ada155e157818a63ee","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":267967963,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":267967963,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_cb864353bcae491b946df1ee3650105d"}},"e244ffb162914c1dbe9b5b89f0e6f242":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_db0909cbb8004cddaf2a2884e23837e6","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 268M/268M [00:03&lt;00:00, 67.5MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c84b98da79954dfe8acddeedd9eaf03e"}},"482044f4db2545ada155e157818a63ee":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"cb864353bcae491b946df1ee3650105d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"db0909cbb8004cddaf2a2884e23837e6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c84b98da79954dfe8acddeedd9eaf03e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"ELKtYgffiaQo"},"source":["!pip install transformers\n","!pip install sent2vec\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3r7vRyjshnx4"},"source":["import warnings\n","from scipy import spatial\n","from sent2vec.vectorizer import Vectorizer\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YWRj8QmPhpeO","executionInfo":{"status":"ok","timestamp":1611849975854,"user_tz":300,"elapsed":17940,"user":{"displayName":"Yang Xu","photoUrl":"","userId":"01537766935427825040"}},"outputId":"af46c25d-84c3-4d49-9345-3675a031550a"},"source":["# Load the Drive helper and mount\n","from google.colab import drive\n","drive.mount('/gdrive', force_remount=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"n4J4zMx2haxk","colab":{"base_uri":"https://localhost:8080/","height":363},"executionInfo":{"status":"error","timestamp":1611849978744,"user_tz":300,"elapsed":325,"user":{"displayName":"Yang Xu","photoUrl":"","userId":"01537766935427825040"}},"outputId":"7010822b-5e8a-4369-9b40-400480a58290"},"source":["import json\n","from pathlib import Path\n","\n","def read_squad(path):\n","    path = Path(path)\n","    with open(path, 'rb') as f:\n","        squad_dict = json.load(f)\n","\n","    contexts = []\n","    questions = []\n","    answers = []\n","    for group in squad_dict['data']:\n","        for passage in group['paragraphs']:\n","            context = passage['context']\n","            for qa in passage['qas']:\n","                question = qa['question']\n","                if qa['answers'] == []:\n","                    answers.append({'text': \"\", 'answer_start': -1, 'answer_end': -1})\n","                    contexts.append(context)\n","                    questions.append(question)\n","                else:\n","                    for answer in qa['answers']:\n","                        answers.append(answer)\n","                        contexts.append(context)\n","                        questions.append(question)\n","\n","    return contexts, questions, answers\n","\n","path = \"/gdrive/MyDrive/ECE692:Project3Paper/\"\n","\n","train_contexts, train_questions, train_answers = read_squad(path + 'json/christie_training.json')\n","val_contexts, val_questions, val_answers = read_squad(path + 'json/christie_validation.json')\n","test_contexts, test_questions, test_answers = read_squad(path + 'json/christie_test.json')\n","\n","# train_contexts, train_questions, train_answers = read_squad(path+'json/christi-snippets_training.json')\n","# val_contexts, val_questions, val_answers = read_squad(path+'json/christi-snippets_val.json')\n","\n","print(len(train_contexts))\n","print(len(val_contexts))"],"execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-38c23e4418ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/gdrive/MyDrive/ECE692:Project3Paper/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mtrain_contexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_questions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_answers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_squad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'json/christie_training.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0mval_contexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_questions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_answers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_squad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'json/christie_validation.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mtest_contexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_questions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_answers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_squad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'json/christie_test.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-38c23e4418ad>\u001b[0m in \u001b[0;36mread_squad\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_squad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0msquad_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/gdrive/MyDrive/ECE692:Project3Paper/json/christie_training.json'"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wNR4AQid1rwt","executionInfo":{"status":"ok","timestamp":1611787049083,"user_tz":300,"elapsed":420,"user":{"displayName":"Tabitha Samuel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhO8chC6osMDib26YnCH60dX2WCDXOlgt3xLueB=s64","userId":"03554413322455311500"}},"outputId":"e7f32e82-8ac2-4f93-fb00-3c2347878c9f"},"source":["def create_question_answers_dict(questions, answers):\n","  q_index = 0\n","  q_a_dict = {}\n","  question = ''\n","  inner_dict = {}\n","  ans_list = []\n","  for q, a in zip(questions, answers):\n","    if q != question:\n","      if (len(ans_list)>0):\n","        inner_dict['answers'] = ans_list\n","        q_a_dict[q_index] = inner_dict\n","        inner_dict = {}\n","        q_index += 1\n","      ans_list = []\n","      inner_dict['question'] = q\n","      question = q\n","      ans_list.append(a['text'])\n","    elif q == question:\n","      ans_list.append(a['text'])\n","      question = q\n","\n","  print(q_a_dict)\n","  return q_a_dict\n"," \n","val_dict = create_question_answers_dict(val_questions, val_answers)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["{0: {'question': \"What did Daniels put on the Prime Minister's face?\", 'answers': ['a pad of chloroform', 'chloroform']}, 1: {'question': 'What does Daniels direct the driver to do', 'answers': ['turn to the right']}, 2: {'question': 'What is the instantaneous anaesthetic', 'answers': ['ethylchloride', 'chloroform']}, 3: {'question': \"Who is the prime minister's secretary?\", 'answers': ['Captain Daniels', 'Daniels']}, 4: {'question': \"What happened to the Prime Minister's face\", 'answers': ['bandaged up', 'face was bandaged up']}, 5: {'question': 'Where did the police of this country hurry to', 'answers': ['across the Channel']}, 6: {'question': 'What was the illusion', 'answers': ['the abduction has taken place in France']}, 7: {'question': 'Who was Mrs. Everard', 'answers': ['Frau Bertha Ebenthal', 'aunt', 'Ebenthal', 'Frau Bertha']}, 8: {'question': 'Where did Frau Bertha Ebenthal and Daniels meet', 'answers': ['']}}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tg-Yju9bZyo4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611765888222,"user_tz":300,"elapsed":373,"user":{"displayName":"Tabitha Samuel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhO8chC6osMDib26YnCH60dX2WCDXOlgt3xLueB=s64","userId":"03554413322455311500"}},"outputId":"dfbf6eec-73ba-4e9f-80fe-56ab00ba631c"},"source":["length = 0\n","\n","for context in train_contexts:\n","  length = length + len(context)\n","avg_length_train = length/len(train_contexts)\n","\n","length = 0\n","\n","for context in val_contexts:\n","  length = length + len(context)\n","avg_length_val = length/len(val_contexts)\n","\n","print(avg_length_train)\n","print(avg_length_val)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2604.8936170212764\n","3979.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"C-n8sw4TcqEM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611765889773,"user_tz":300,"elapsed":374,"user":{"displayName":"Tabitha Samuel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhO8chC6osMDib26YnCH60dX2WCDXOlgt3xLueB=s64","userId":"03554413322455311500"}},"outputId":"9eefb17e-ff79-4959-cc71-3462c300fc5b"},"source":["length = 0\n","print(len(train_answers))\n","print(len(val_answers))\n","\n","for ans in train_answers:\n","  answer = ans['text']\n","  length = length + len(answer)\n","  \n","avg_length_train = length/len(train_answers)\n","\n","length = 0\n","\n","for ans in val_answers:\n","  answer = ans['text']\n","  length = length + len(answer)\n","avg_length_val = length/len(val_answers)\n","\n","print(train_answers[:10])\n","print(avg_length_train)\n","print(avg_length_val)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["47\n","17\n","[{'text': 'England', 'answer_start': 1650}, {'text': 'Peace by negotiation', 'answer_start': 568}, {'text': 'Peace', 'answer_start': 568}, {'text': 'a grey suit with a minute sponge', 'answer_start': 1796}, {'text': 'a grey suit', 'answer_start': 1796}, {'text': 'suit', 'answer_start': 1803}, {'text': 'a minute sponge', 'answer_start': 1813}, {'text': 'a minute sponge', 'answer_start': 1813}, {'text': 'a minute sponge', 'answer_start': 1813}, {'text': 'a minute sponge', 'answer_start': 1813}]\n","15.340425531914894\n","13.058823529411764\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Kh0fb-M-iHhi"},"source":["First, let’s get the character position at which the answer ends in the passage (we are given the starting position). Sometimes SQuAD answers are off by one or two characters, so we will also adjust for that."]},{"cell_type":"code","metadata":{"id":"9QNcEGALiGWr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611774294098,"user_tz":300,"elapsed":391,"user":{"displayName":"Tabitha Samuel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhO8chC6osMDib26YnCH60dX2WCDXOlgt3xLueB=s64","userId":"03554413322455311500"}},"outputId":"d3e25ee7-4e27-4475-a9aa-1b81f687038f"},"source":["def add_end_idx(answers, contexts):\n","    for answer, context in zip(answers, contexts):\n","\n","        if answer['answer_start'] == -1:\n","          continue\n","\n","        gold_text = answer['text']\n","        start_idx = answer['answer_start']\n","        print(gold_text)\n","        end_idx = start_idx + len(gold_text)\n","        \n","        # sometimes squad answers are off by a character or two – fix this\n","        if context[start_idx:end_idx] == gold_text:\n","            \n","            answer['answer_end'] = end_idx\n","        elif context[start_idx-1:end_idx-1] == gold_text:\n","           \n","            answer['answer_start'] = start_idx - 1\n","            answer['answer_end'] = end_idx - 1     # When the gold label is off by one character\n","        elif context[start_idx-2:end_idx-2] == gold_text:\n","           \n","            answer['answer_start'] = start_idx - 2\n","            answer['answer_end'] = end_idx - 2     # When the gold label is off by two characters\n","\n","       \n","add_end_idx(train_answers, train_contexts)\n","add_end_idx(val_answers, val_contexts)\n","print(len(val_answers))\n","print(len(train_answers))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["England\n","Peace by negotiation\n","Peace\n","a grey suit with a minute sponge\n","a grey suit\n","suit\n","a minute sponge\n","a minute sponge\n","a minute sponge\n","a minute sponge\n","Neatness and order\n","Neatness and order\n","Neatness and order\n","Neatness and order\n","an attempted assassination of Mr. David MacAdam\n","an attempted assassination\n","attempted assassination of Mr. David MacAdam\n","an attempted assassination of Mr. David MacAdam\n","David MacAdam\n","David\n","MacAdam\n","Fighting Mac\n","in bed\n","sitting up in bed\n","bed\n","terror of evil-doers\n","terror of evil\n","terror\n","a convalescent influenza patient\n","influenza patient\n","a convalescent\n","a particularly noxious tisane\n","noxious tisane\n","tisane\n","own pet society detective\n","society detective\n","Poirot\n","Hercule\n","Second son of fifth Baron Windsor\n","in a woollen shawl\n","shawl\n","Our landlady\n","landlady\n","a pad of chloroform\n","chloroform\n","turn to the right\n","ethylchloride\n","chloroform\n","Captain Daniels\n","Daniels\n","bandaged up\n","face was bandaged up\n","across the Channel\n","the abduction has taken place in France\n","Frau Bertha Ebenthal\n","aunt\n","Ebenthal\n","Frau Bertha\n","17\n","47\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"uNl3GhMSiQYS"},"source":["Now train_answers and val_answers include the character end positions and the corrected start positions. Next, let’s tokenize our context/question pairs. Tokenizers can accept parallel lists of sequences and encode them together as sequence pairs."]},{"cell_type":"code","metadata":{"id":"NSssP5phiHNe","colab":{"base_uri":"https://localhost:8080/","height":115,"referenced_widgets":["b68304ea5e36411aae7636318f0be5e2","a30baef17aa84d5ca9d37c67bc7aea2a","cc973cc3b1494c0c93444e6a6f992a18","160b6a16267344daa1972e26d67a3775","3b02be962a1b4ed3a18fd1fff8e00f61","a35f1c628b264ce5ae32ef67c5eced2e","a6bd88e147f84e6791b7b1ff8dacb6ab","095f0a319ea044138c36e6856f5e82ad","b5f0f5a5477a4bdd84ff75b336a40637","c8c43401ccec43578883b6cba3d91ad7","906fa06e6f1847d0aac133c6a28ccfc2","a16fddb3c717484a87fdfc9f77ca9301","d8fd5991adff47a6ac0f9fe1f2a31865","94bdb9c2063e44f5973a87c5b16d5f2c","b983adb444ba49c2954a63d288d8be01","0de889d804a046ecb5b605692f78e02b"]},"executionInfo":{"status":"ok","timestamp":1611773879572,"user_tz":300,"elapsed":936,"user":{"displayName":"Tabitha Samuel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhO8chC6osMDib26YnCH60dX2WCDXOlgt3xLueB=s64","userId":"03554413322455311500"}},"outputId":"4443f16a-5273-4166-f777-8371c5d29927"},"source":["from transformers import DistilBertTokenizerFast\n","# tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n","tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased-distilled-squad')\n","\n","train_encodings = tokenizer(train_contexts, train_questions, truncation=True, padding=True)\n","val_encodings = tokenizer(val_contexts, val_questions, truncation=True, padding=True)\n","\n","# print(val_encodings)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b68304ea5e36411aae7636318f0be5e2","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b5f0f5a5477a4bdd84ff75b336a40637","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0Kio7mthilIg"},"source":["Next we need to convert our character start/end positions to token start/end positions. When using 🤗 Fast Tokenizers, we can use the built in char_to_token() method."]},{"cell_type":"code","metadata":{"id":"KSfO8Jb0ip9t"},"source":["def add_token_positions(encodings, answers):\n","    start_positions = []\n","    end_positions = []\n","    for i in range(len(answers)):\n","        if answers[i]['answer_start'] == -1:\n","            start_positions.append(tokenizer.model_max_length)\n","            end_positions.append(tokenizer.model_max_length)\n","            continue\n","        # print(answers[i])\n","        start_positions.append(encodings.char_to_token(i, answers[i]['answer_start']))\n","        end_positions.append(encodings.char_to_token(i, answers[i]['answer_end'] - 1))\n","        # if None, the answer passage has been truncated\n","        if start_positions[-1] is None:\n","            start_positions[-1] = tokenizer.model_max_length\n","        if end_positions[-1] is None:\n","            end_positions[-1] = tokenizer.model_max_length\n","    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n","    \n","add_token_positions(train_encodings, train_answers)\n","add_token_positions(val_encodings, val_answers)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MYxJd0lHi0ed"},"source":["Our data is ready. Let’s just put it in a PyTorch/TensorFlow dataset so that we can easily use it for training. In PyTorch, we define a custom Dataset class. In TensorFlow, we pass a tuple of (inputs_dict, labels_dict) to the from_tensor_slices method."]},{"cell_type":"code","metadata":{"id":"fb3k4ZBAi2OI"},"source":["import torch\n","\n","class SquadDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings):\n","        self.encodings = encodings\n","\n","    def __getitem__(self, idx):\n","        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","\n","    def __len__(self):\n","        return len(self.encodings.input_ids)\n","\n","train_dataset = SquadDataset(train_encodings)\n","val_dataset = SquadDataset(val_encodings)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H8ZpUqDwi4YN"},"source":["Now we can use a DistilBert model with a QA head for training:"]},{"cell_type":"markdown","metadata":{"id":"gj-TnDIV94Qg"},"source":["Get pre fine-tuned accuracy on validation set"]},{"cell_type":"code","metadata":{"id":"2UaIpik093nW","colab":{"base_uri":"https://localhost:8080/","height":252,"referenced_widgets":["8946e465ba8c428ab9891731dc49ec36","5a92436f43964b8b8affe54252977a17","0e882124f5bb45d5a4aa7d2cd7e7413f","4c104617820e46879d553ae173a5b8c1","1233df069a504af68461f94f9073799d","d4ea9497613f4848950e49e4c4e5d7fd","6adba28b38b4442e9fb33a3a8c7c0ecf","257b047b5105446b9e81cc02d4199354","0576dff7461c4b99a9d02f06a43567d6","ff368e32e73a4a5a8b8c0060b360ad32","13bd49e5a8b24b74a95115b91df92afb","09f142c780424faaa3447ad183aa083d","0de6f119d49244bd86758b816d565a3c","6064e702bf074b05a3b7bb27877238bb","c13c95ba55444c79a48e0ba6e21ace40","ddeb5cee7af949c2b4171e494c56ebf3","c4662ceb1d2a44e0bd7a1cad08c70c3b","a0c9cdb0fc954ff9bbe6d264a760be9c","ce3e2c06432a49ca8aa2bd1952adf08f","e244ffb162914c1dbe9b5b89f0e6f242","482044f4db2545ada155e157818a63ee","cb864353bcae491b946df1ee3650105d","db0909cbb8004cddaf2a2884e23837e6","c84b98da79954dfe8acddeedd9eaf03e"]},"executionInfo":{"status":"ok","timestamp":1611773957878,"user_tz":300,"elapsed":27358,"user":{"displayName":"Tabitha Samuel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhO8chC6osMDib26YnCH60dX2WCDXOlgt3xLueB=s64","userId":"03554413322455311500"}},"outputId":"cc379668-cb27-4d12-f1a5-99dd886b3989"},"source":["from transformers import DistilBertForQuestionAnswering\n","# model = DistilBertForQuestionAnswering.from_pretrained(\"distilbert-base-uncased\")\n","model = DistilBertForQuestionAnswering.from_pretrained(\"distilbert-base-uncased-distilled-squad\")\n","\n","#Test on validation set\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","# device = torch.device('cpu')\n","vectorizer = Vectorizer()\n","\n","questions_count = len(val_questions)\n","model.to(device)\n","correct = 0\n","correct_cosine = 0\n","for i in range(len(val_questions)):\n","  context = val_contexts[i]\n","  question = val_questions[i]\n","  answer = val_answers[i]\n","\n","  encoding = tokenizer.encode_plus(question, context, max_length=512)\n","  input_ids, attention_mask = encoding[\"input_ids\"], encoding[\"attention_mask\"]\n","  start_scores, end_scores = model(torch.tensor([input_ids], device=device), \n","                                   attention_mask=torch.tensor([attention_mask],\n","                                    device=device), return_dict=False)\n","  ans_tokens = input_ids[torch.argmax(start_scores.cpu()) : torch.argmax(end_scores.cpu())+1]\n","  answer_tokens = tokenizer.convert_ids_to_tokens(ans_tokens , skip_special_tokens=True)\n","  all_tokens = tokenizer.convert_ids_to_tokens(input_ids)\n","  # print(val_questions[i])\n","  answer_tokens_to_string = tokenizer.convert_tokens_to_string(answer_tokens)\n","  # print('Predicted: %s Actual: %s'%(answer_tokens_to_string, answer['text']))\n","  if answer_tokens_to_string == '' and answer['text'] != '' or answer_tokens_to_string != '' and answer['text'] == '':\n","    # print('edge case..skipping')\n","    continue\n","  vectorizer.bert([answer_tokens_to_string, answer['text'].lower() ])\n","  vectors_bert = vectorizer.vectors\n","  dist_answer = spatial.distance.cosine(vectors_bert[0], vectors_bert[1])\n","  # print(dist_answer)\n","  if dist_answer < 0.03:\n","    # print('cosine correct')\n","    correct_cosine += 1\n"," \n","  if(answer_tokens_to_string.lower() in answer['text'].lower())or (answer['text'].lower() in answer_tokens_to_string.lower() ):\n","    # print('text correct')\n","    correct += 1\n","print('Num correct cosine: %d, correct text: %d'%(correct_cosine, correct))\n","print(\"Validation Set Accuracy: {}!\".format(correct / questions_count))    \n","print(\"Validation Set Accuracy cosine: {}!\".format(correct_cosine / questions_count)) "],"execution_count":null,"outputs":[{"output_type":"stream","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8946e465ba8c428ab9891731dc49ec36","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0576dff7461c4b99a9d02f06a43567d6","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=442.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c4662ceb1d2a44e0bd7a1cad08c70c3b","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=267967963.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Num correct cosine: 5, correct text: 6\n","Validation Set Accuracy: 0.35294117647058826!\n","Validation Set Accuracy cosine: 0.29411764705882354!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RWwQu8_Gi8P4"},"source":["The data and model are both ready to go. You can train the model with Trainer/TFTrainer exactly as in the sequence classification example above. If using native PyTorch, replace labels with start_positions and end_positions in the training example. If using Keras’s fit, we need to make a minor modification to handle this example since it involves multiple model outputs."]},{"cell_type":"markdown","metadata":{"id":"zvKCyLg8clXf"},"source":["Option A: The steps above prepared the datasets in the way that the trainer is expected. Now all we need to do is create a model to fine-tune, define the TrainingArguments/TFTrainingArguments and instantiate a Trainer/TFTrainer."]},{"cell_type":"code","metadata":{"id":"vvPNJtERhK9U"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EePMIVtscYQv","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1611774051134,"user_tz":300,"elapsed":32300,"user":{"displayName":"Tabitha Samuel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhO8chC6osMDib26YnCH60dX2WCDXOlgt3xLueB=s64","userId":"03554413322455311500"}},"outputId":"ffe7a9d9-0398-4869-e554-64132801ad61"},"source":["from transformers import DistilBertForQuestionAnswering\n","# model = DistilBertForQuestionAnswering.from_pretrained(\"distilbert-base-uncased\")\n","model = DistilBertForQuestionAnswering.from_pretrained(\"distilbert-base-uncased-distilled-squad\")\n","\n","## best results so far per device train/eval batch size = 16, epochs = 2\n","\n","from transformers import Trainer, TrainingArguments\n","\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","# device = torch.device('cpu')\n","model.to(device)\n","training_args = TrainingArguments(\n","    output_dir='./results',          # output directory\n","    num_train_epochs=2,              # total number of training epochs\n","    per_device_train_batch_size=16,  # batch size per device during training\n","    per_device_eval_batch_size=16,   # batch size for evaluation\n","    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n","    weight_decay=0.01,               # strength of weight decay\n","    logging_dir='./logs',            # directory for storing logs\n","    logging_steps=1,\n","    learning_rate = 0.001\n","    \n",")\n","\n","\n","\n","trainer = Trainer(\n","    model=model,                         # the instantiated 🤗 Transformers model to be trained\n","    args=training_args,                  # training arguments, defined above\n","    train_dataset=train_dataset,         # training dataset\n","    eval_dataset=val_dataset             # evaluation dataset\n",")\n","\n","trainer.train()\n","\n","#Test on validation set\n","questions_count = len(val_questions)\n","\n","correct = 0\n","correct_cosine = 0\n","\n","vectorizer = Vectorizer()\n","for i in range(len(val_questions)):\n","  context = val_contexts[i]\n","  question = val_questions[i]\n","  answer = val_answers[i]\n","\n","  \n","  encoding = tokenizer.encode_plus(question, context, max_length=512)\n","  input_ids, attention_mask = encoding[\"input_ids\"], encoding[\"attention_mask\"]\n","  start_scores, end_scores =  model(torch.tensor([input_ids], device=device), attention_mask=torch.tensor([attention_mask], device=device), return_dict=False)\n","  ans_tokens = input_ids[torch.argmax(start_scores.cpu()) : torch.argmax(end_scores.cpu())+1]\n","  answer_tokens = tokenizer.convert_ids_to_tokens(ans_tokens , skip_special_tokens=True)\n","  all_tokens = tokenizer.convert_ids_to_tokens(input_ids)\n","  answer_tokens_to_string = tokenizer.convert_tokens_to_string(answer_tokens)\n","  print(val_questions[i])\n","  print('Prediction: %s Actual: %s '%(answer_tokens_to_string, answer['text']))\n","  if (answer_tokens_to_string == '' and answer['text'] != '') or (answer_tokens_to_string != '' and answer['text'] == ''):\n","    continue\n","  vectorizer.bert([answer_tokens_to_string.lower(), answer['text'].lower() ])\n","  vectors_bert = vectorizer.vectors\n","  dist_answer = spatial.distance.cosine(vectors_bert[0], vectors_bert[1])\n","  \n","  if dist_answer < 0.03:\n","    correct_cosine += 1\n","    print('cosine correct')\n","  else:\n","    print('cosine incorrect')  \n","  if(answer_tokens_to_string.lower() in answer['text'].lower()) or (answer['text'].lower() in answer_tokens_to_string.lower()):\n","    correct += 1\n","    print('text correct')\n","  else:\n","    print('text incorrect')  \n","\n","\n","print(correct)  \n","print(\"Validation Set Accuracy: {}!\".format(correct / questions_count))\n","print(correct_cosine)     \n","print(\"Validation Set Accuracy Cosine: {}!\".format(correct_cosine / questions_count))"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [6/6 00:03, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>9.601900</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>9.597500</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>9.386900</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>8.843600</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>7.712600</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>7.124100</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["What did Daniels put on the Prime Minister's face?\n","Prediction: a pad of chloroform Actual: a pad of chloroform \n","cosine correct\n","text correct\n","What did Daniels put on the Prime Minister's face?\n","Prediction: a pad of chloroform Actual: chloroform \n","cosine correct\n","text correct\n","What does Daniels direct the driver to do\n","Prediction: o ’ murphy Actual: turn to the right \n","cosine incorrect\n","text incorrect\n","What is the instantaneous anaesthetic\n","Prediction: ethylchloride Actual: ethylchloride \n","cosine correct\n","text correct\n","What is the instantaneous anaesthetic\n","Prediction: ethylchloride Actual: chloroform \n","cosine correct\n","text incorrect\n","Who is the prime minister's secretary?\n","Prediction: captain daniels Actual: Captain Daniels \n","cosine correct\n","text correct\n","Who is the prime minister's secretary?\n","Prediction: captain daniels Actual: Daniels \n","cosine correct\n","text correct\n","What happened to the Prime Minister's face\n","Prediction: the prime minister has never left england. he was kidnapped on his way from windsor to london. ” “ what? ” the prime minister was in his car, his secretary beside him. suddenly a pad of chloroform is clapped on his face — — ” “ but by whom? ” “ by the clever linguistic captain daniels Actual: bandaged up \n","cosine incorrect\n","text incorrect\n","What happened to the Prime Minister's face\n","Prediction: a pad of chloroform is clapped on his face — — ” “ but by whom? ” “ by the clever linguistic captain daniels. as soon as the prime minister is unconscious, daniels picks up the speaking - tube, and directs o ’ murphy to turn to the right, which the chauffeur, quite unsuspicious, does. a few yards down that unfrequented road, a large car is standing, apparently broken down. its driver signals to o ’ murphy to stop. o ’ murphy slows up. the stranger approaches. daniels leans out of the window, and, probably with the aid of an instantaneous anæsthetic, such as ethylchloride, the chloroform trick is repeated. in a few seconds, the two helpless men are dragged out and transferred to the other car, and a pair of substitutes take their places. ” “ impossible! ” “ pas du tout! have you not seen music - hall turns imitating celebrities with marvellous accuracy? nothing is easier than to personate a public character. the prime minister of england is far easier to understudy than mr. john smith of clapham, say. as for o ’ murphy ’ s ‘ double, ’ no one was going to take much notice of him until after the departure of the prime minister, and by then he would have made himself scarce. he drives straight from charing cross to the meeting - place of his friends. he goes in as o ’ murphy, he emerges as some one quite different. o ’ murphy has disappeared, leaving a conveniently suspicious trail behind him. ” “ but the man who personated the prime minister was seen by every one! ” “ he was not seen by anyone who knew him privately or intimately. and daniels shielded him from contact with anyone as much as possible. moreover, his face was bandaged up Actual: face was bandaged up \n","cosine incorrect\n","text correct\n","Where did the police of this country hurry to\n","Prediction: where did the police of this country hurry to “ for heaven ’ s sake, tell me all about it, ” i cried impatiently, as poirot, norman, and i motored back to london Actual: across the Channel \n","cosine incorrect\n","text incorrect\n","What was the illusion\n","Prediction:  Actual: the abduction has taken place in France \n","Who was Mrs. Everard\n","Prediction: captain daniels Actual: Frau Bertha Ebenthal \n","cosine incorrect\n","text incorrect\n","Who was Mrs. Everard\n","Prediction: captain daniels Actual: aunt \n","cosine correct\n","text incorrect\n","Who was Mrs. Everard\n","Prediction: captain daniels Actual: Ebenthal \n","cosine incorrect\n","text incorrect\n","Who was Mrs. Everard\n","Prediction: captain daniels Actual: Frau Bertha \n","cosine incorrect\n","text incorrect\n","Where did Frau Bertha Ebenthal and Daniels meet\n","Prediction: charing cross Actual:  \n","How old is Daniels\n","Prediction:  Actual:  \n","cosine correct\n","text correct\n","7\n","Validation Set Accuracy: 0.4117647058823529!\n","8\n","Validation Set Accuracy Cosine: 0.47058823529411764!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-3oIot_pFAto"},"source":["Option B: native PyTorch "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":449},"id":"XzbXStrpi_WM","executionInfo":{"status":"ok","timestamp":1611774086433,"user_tz":300,"elapsed":24852,"user":{"displayName":"Tabitha Samuel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhO8chC6osMDib26YnCH60dX2WCDXOlgt3xLueB=s64","userId":"03554413322455311500"}},"outputId":"ee90d636-4dfd-4ff7-9fbb-dd01f1296f77"},"source":["from torch.utils.data import DataLoader\n","from transformers import AdamW\n","from transformers import DistilBertForQuestionAnswering\n","\n","\n","model = DistilBertForQuestionAnswering.from_pretrained(\"distilbert-base-uncased-distilled-squad\")\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","\n","model.to(device)\n","model.train()\n","\n","train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n","losses = []\n","optim = AdamW(model.parameters(), lr=0.00001, weight_decay=0.001)\n","\n","for epoch in range(10):\n","    for batch in train_loader:\n","        optim.zero_grad()\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        start_positions = batch['start_positions'].to(device)\n","        end_positions = batch['end_positions'].to(device)\n","        outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n","        loss = outputs[0]\n","        loss.backward()\n","        optim.step()\n","        current_loss = loss.item()\n","    print(\"Iteration {} Current Loss {} Batch Loss {}\".format(epoch, current_loss, loss.item()))\n","    losses.append(current_loss)\n","model.eval()\n","\n","import matplotlib.pyplot as plt\n","plt.plot(range(len(losses)), losses)\n","plt.xlabel('epochs')\n","plt.ylabel('loss')\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Iteration 0 Current Loss 7.198125839233398 Batch Loss 7.198125839233398\n","Iteration 1 Current Loss 5.271439552307129 Batch Loss 5.271439552307129\n","Iteration 2 Current Loss 4.222354412078857 Batch Loss 4.222354412078857\n","Iteration 3 Current Loss 4.488497734069824 Batch Loss 4.488497734069824\n","Iteration 4 Current Loss 4.768744945526123 Batch Loss 4.768744945526123\n","Iteration 5 Current Loss 2.5914626121520996 Batch Loss 2.5914626121520996\n","Iteration 6 Current Loss 3.0594687461853027 Batch Loss 3.0594687461853027\n","Iteration 7 Current Loss 3.688427686691284 Batch Loss 3.688427686691284\n","Iteration 8 Current Loss 2.4071664810180664 Batch Loss 2.4071664810180664\n","Iteration 9 Current Loss 3.0741055011749268 Batch Loss 3.0741055011749268\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"33L0jP-smF09"},"source":["**Next Step: Is to Test on a Question**"]},{"cell_type":"code","metadata":{"id":"iCnTCUw-mChd","colab":{"base_uri":"https://localhost:8080/","height":286},"executionInfo":{"status":"error","timestamp":1611774113374,"user_tz":300,"elapsed":893,"user":{"displayName":"Tabitha Samuel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhO8chC6osMDib26YnCH60dX2WCDXOlgt3xLueB=s64","userId":"03554413322455311500"}},"outputId":"0773ae73-61da-40c9-b80d-b0fe40a62435"},"source":["#Test using a question from the test dataset\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","# device = torch.device('cpu')\n","questions_count = len(train_questions)\n","\n","correct = 0\n","\n","for i in range(questions_count):\n","  context = train_contexts[i]\n","  question = train_questions[i]\n","  answer = train_answers[i]\n","\n","  #print(answer['text'].lower())\n","\n","  encoding = tokenizer.encode_plus(question, context, max_length=512)\n","\n","  input_ids, attention_mask = encoding[\"input_ids\"], encoding[\"attention_mask\"]\n","\n","  start_scores, end_scores = model(torch.tensor([input_ids], device=device), attention_mask=torch.tensor([attention_mask], device=device), return_dict=False)\n","\n","  ans_tokens = input_ids[torch.argmax(start_scores) : torch.argmax(end_scores)+1]\n","  answer_tokens = tokenizer.convert_ids_to_tokens(ans_tokens , skip_special_tokens=True)\n","\n","  all_tokens = tokenizer.convert_ids_to_tokens(input_ids)\n","  answer_tokens_to_string = tokenizer.convert_tokens_to_string(answer_tokens)\n","\n","  if(answer_tokens_to_string in answer['text'].lower()):\n","    correct += 1\n","  print(\"Training Set Accuracy: {}!\".format(correct / questions_count))\n","  print(\"Question: {}\\nAnswer {}\".format(question, answer_tokens_to_string))\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (738 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-536388549bdf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0mstart_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m   \u001b[0mans_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_scores\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m   \u001b[0manswer_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_ids_to_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans_tokens\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"]}]},{"cell_type":"code","metadata":{"id":"DgkuHVHjmHL_","colab":{"base_uri":"https://localhost:8080/","height":249},"executionInfo":{"status":"error","timestamp":1611774155781,"user_tz":300,"elapsed":304,"user":{"displayName":"Tabitha Samuel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhO8chC6osMDib26YnCH60dX2WCDXOlgt3xLueB=s64","userId":"03554413322455311500"}},"outputId":"e0eb7a0f-771f-47f5-eaa1-20f22a1abf2f"},"source":["#Test on validation set\n","questions_count = len(val_questions)\n","\n","correct = 0\n","correct_cosine = 0\n","\n","vectorizer = Vectorizer()\n","for i in range(len(val_questions)):\n","  context = val_contexts[i]\n","  question = val_questions[i]\n","  answer = val_answers[i]\n","\n","  # print(context)\n","  # print(question)\n","  # print(answer)\n","  encoding = tokenizer.encode_plus(question, context, max_length=512)\n","  input_ids, attention_mask = encoding[\"input_ids\"], encoding[\"attention_mask\"]\n","  start_scores, end_scores = model(torch.tensor([input_ids], device=device), attention_mask=torch.tensor([attention_mask], device=device), return_dict=False)\n","  ans_tokens = input_ids[torch.argmax(start_scores.cpu()) : torch.argmax(end_scores.cpu())+1]\n","  answer_tokens = tokenizer.convert_ids_to_tokens(ans_tokens , skip_special_tokens=True)\n","  all_tokens = tokenizer.convert_ids_to_tokens(input_ids)\n","  answer_tokens_to_string = tokenizer.convert_tokens_to_string(answer_tokens)\n","  print('Predicted: %s Actual %s'%(answer_tokens_to_string, answer['text']))\n","  if (answer_tokens_to_string == '' and answer['text'] != '') or (answer_tokens_to_string != '' and answer['text'] == ''):\n","    continue\n","  vectorizer.bert([answer_tokens_to_string.lower(), answer['text'].lower() ])\n","  vectors_bert = vectorizer.vectors\n","  dist_answer = spatial.distance.cosine(vectors_bert[0], vectors_bert[1])\n","  \n","  if dist_answer < 0.03:\n","    print('cosine correct')\n","    correct_cosine += 1\n","  else:\n","    print('cosine incorrect')  \n","  if(answer_tokens_to_string.lower() in answer['text'].lower()) or (answer['text'].lower() in answer_tokens_to_string.lower()):\n","    print('text correct')\n","    correct += 1\n","  else:\n","    print('text incorrect')   \n","  \n","\n","print(correct)  \n","print(\"Validation Set Accuracy: {}!\".format(correct / questions_count))\n","print(correct_cosine)     \n","print(\"Validation Set Accuracy Cosine: {}!\".format(correct_cosine / questions_count))"],"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-176f8e74a49f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_plus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"attention_mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m   \u001b[0mstart_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m   \u001b[0mans_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0manswer_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_ids_to_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans_tokens\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lzGf2WNBr8OS","executionInfo":{"elapsed":2548,"status":"ok","timestamp":1606083907124,"user":{"displayName":"Tabitha Samuel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhO8chC6osMDib26YnCH60dX2WCDXOlgt3xLueB=s64","userId":"03554413322455311500"},"user_tz":300},"outputId":"ce71928e-c947-4e52-eeb6-f0bb525ff82b"},"source":["\n","sentences = [\n","    \"house of ‘ mrs. everard\",\n","    \"Mrs. Everard,'\",\n","    \"hampstead\",\n","    \"a pad of chloroform\",\n","    \"chloroform\",\n","]\n","\n","\n","\n","vectorizer.bert(sentences)\n","vectors_bert = vectorizer.vectors\n","\n","dist_1 = spatial.distance.cosine(vectors_bert[0], vectors_bert[1])\n","dist_2 = spatial.distance.cosine(vectors_bert[3], vectors_bert[4])\n","#dist_3 = spatial.distance.cosine(vectors_bert[2], vectors_bert[1])\n","print('dist_1: {0}, '.format(dist_1))\n","print('dist_2: {0}, '.format(dist_2))\n","#print('dist_3: {0}, '.format(dist_3))\n","# dist_1: 0.043, dist_2: 0.192"],"execution_count":null,"outputs":[{"output_type":"stream","text":["dist_1: 0.0329669713973999, \n","dist_2: 0.02843719720840454, \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":835},"id":"xz3fAK8ItLGu","executionInfo":{"status":"ok","timestamp":1611850352540,"user_tz":300,"elapsed":7278,"user":{"displayName":"Yang Xu","photoUrl":"","userId":"01537766935427825040"}},"outputId":"d7840cda-f973-4d2f-9130-6790e8bd7ba0"},"source":["##install BLEU score\r\n","!pip install bleu\r\n","!pip install --upgrade nltk"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: bleu in /usr/local/lib/python3.6/dist-packages (0.3)\n","Requirement already satisfied: efficiency in /usr/local/lib/python3.6/dist-packages (from bleu) (0.4)\n","Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (from efficiency->bleu) (2.2.4)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy->efficiency->bleu) (1.0.5)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->efficiency->bleu) (2.0.5)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy->efficiency->bleu) (1.19.5)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->efficiency->bleu) (0.4.1)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy->efficiency->bleu) (1.0.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy->efficiency->bleu) (4.41.1)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->efficiency->bleu) (7.4.0)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->efficiency->bleu) (1.0.5)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy->efficiency->bleu) (2.23.0)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->efficiency->bleu) (3.0.5)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy->efficiency->bleu) (1.1.3)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->efficiency->bleu) (0.8.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy->efficiency->bleu) (51.3.3)\n","Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->efficiency->bleu) (3.4.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->efficiency->bleu) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->efficiency->bleu) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->efficiency->bleu) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->efficiency->bleu) (2.10)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->efficiency->bleu) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->efficiency->bleu) (3.4.0)\n","Collecting nltk\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/75/ce35194d8e3022203cca0d2f896dbb88689f9b3fce8e9f9cff942913519d/nltk-3.5.zip (1.4MB)\n","\u001b[K     |████████████████████████████████| 1.4MB 16.1MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from nltk) (7.1.2)\n","Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.6/dist-packages (from nltk) (1.0.0)\n","Requirement already satisfied, skipping upgrade: regex in /usr/local/lib/python3.6/dist-packages (from nltk) (2019.12.20)\n","Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from nltk) (4.41.1)\n","Building wheels for collected packages: nltk\n","  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for nltk: filename=nltk-3.5-cp36-none-any.whl size=1434675 sha256=b39805354b956cb594100a37d342639f28fd1e01c3ca24733caa8d183c88a7f4\n","  Stored in directory: /root/.cache/pip/wheels/ae/8c/3f/b1fe0ba04555b08b57ab52ab7f86023639a526d8bc8d384306\n","Successfully built nltk\n","Installing collected packages: nltk\n","  Found existing installation: nltk 3.2.5\n","    Uninstalling nltk-3.2.5:\n","      Successfully uninstalled nltk-3.2.5\n","Successfully installed nltk-3.5\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["nltk"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ef9vHDN2uTxV","executionInfo":{"status":"ok","timestamp":1611851044267,"user_tz":300,"elapsed":1425,"user":{"displayName":"Yang Xu","photoUrl":"","userId":"01537766935427825040"}},"outputId":"373e9094-1519-4941-f446-4fd0943b2a99"},"source":["from bleu import list_bleu,multi_list_bleu ##import bleu metric\r\n","from nltk.translate import meteor_score ## import meteor metric\r\n","import nltk\r\n","nltk.download('wordnet')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CQqKe00Put79","executionInfo":{"status":"ok","timestamp":1611850745581,"user_tz":300,"elapsed":486,"user":{"displayName":"Yang Xu","photoUrl":"","userId":"01537766935427825040"}},"outputId":"f68bf5b3-8404-4b29-91f9-ec8ab83c4e08"},"source":["##Use of bleu with example answers\r\n","answers = [[\"answer of question 1\"],[\"answer of question 1\"]]\r\n","prediction = [['answer of question 1'],['answer of question 1']]\r\n","bleu_score = multi_list_bleu(answers,prediction)\r\n","print(bleu_score)\r\n","\r\n","##when there are multiple right answers for one question\r\n","answers = [[\"answer of question 1\"],[\"alternative answer of Q1\"]]##each right answer is in a list\r\n","prediction = ['alternative answer of Q1']\r\n","bleu_score = list_bleu(answers,prediction)\r\n","print(bleu_score)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[100.0, 100.0]\n","100.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zWf1d0IMxW8_","executionInfo":{"status":"ok","timestamp":1611851062472,"user_tz":300,"elapsed":394,"user":{"displayName":"Yang Xu","photoUrl":"","userId":"01537766935427825040"}},"outputId":"7d1c32ac-77ec-4d5a-9503-1af6b9eff2d4"},"source":["##Use of meteor with example answers\r\n","##when there are multiple right answers for one question\r\n","answers = [\"answer of question 1\",\"alternative answer of Q1\"]##all right answers in one list\r\n","prediction = 'alternative answer of Q1' ## a string not a list\r\n","meteor_scores = meteor_score.meteor_score(answers,prediction)\r\n","print(meteor_scores)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0.9921875\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uyOlY1qP0wHG"},"source":["import numpy as np\r\n","#Test on validation set\r\n","questions_count = len(val_questions)\r\n","\r\n","bleu_scores = []\r\n","meteor_scores = []\r\n","\r\n","vectorizer = Vectorizer()\r\n","for i in range(len(val_questions)):\r\n","  context = val_contexts[i]\r\n","  question = val_questions[i]\r\n","  answer = val_answers[i]\r\n","  \r\n","  encoding = tokenizer.encode_plus(question, context, max_length=512)\r\n","  input_ids, attention_mask = encoding[\"input_ids\"], encoding[\"attention_mask\"]\r\n","  start_scores, end_scores =  model(torch.tensor([input_ids], device=device), attention_mask=torch.tensor([attention_mask], device=device), return_dict=False)\r\n","  ans_tokens = input_ids[torch.argmax(start_scores.cpu()) : torch.argmax(end_scores.cpu())+1]\r\n","  answer_tokens = tokenizer.convert_ids_to_tokens(ans_tokens , skip_special_tokens=True)\r\n","  all_tokens = tokenizer.convert_ids_to_tokens(input_ids)\r\n","  answer_tokens_to_string = tokenizer.convert_tokens_to_string(answer_tokens)\r\n","  \r\n","  bleu_scores.append(list_bleu([answer['text']],[answer_tokens_to_string]))\r\n","  meteor_scores.append(meteor_score.meteor_score([answer['text']],answer_tokens_to_string))\r\n","\r\n","print(np.mean(bleu_scores))\r\n","print(bleu_scores)\r\n","print(np.mean(meteor_scores))\r\n","print(meteor_scores)"],"execution_count":null,"outputs":[]}]}